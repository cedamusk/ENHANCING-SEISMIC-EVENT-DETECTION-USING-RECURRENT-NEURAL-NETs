{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYJAjQWPDfNE+pDFlkvN5s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cedamusk/final-year/blob/main/finalyearproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enhancing Seismic Event Detection Using Recurrent Neural Networks on STA/LTA Detection Algorithm\n",
        "\n",
        "## Introduction\n",
        "The Short-Term Average/ Long-Term Average (STA/LTA) detection algoritm is a widely used method in seismic event detection commonly employed in real-time seismic monitoring systems to automatically identify earthquakes.\n",
        "\n",
        "Recurrent Neural Networks are a type of Artificial Neural Network that are specifically designed to handle sequential data by incorporating feedback loops that allow information to persist across time steps.\n",
        "\n",
        "The purpose of this script is to enhance the detection of seismic events by using an RNN model on the STA/LTA detection algorithm.\n",
        "\n"
      ],
      "metadata": {
        "id": "pJYStZ8WJW10"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1X485J7Sx4t8",
        "outputId": "48bd80ad-3d16-4c90-b451-13faed6bd600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: obspy in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from obspy) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from obspy) (1.13.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from obspy) (5.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from obspy) (75.1.0)\n",
            "Requirement already satisfied: sqlalchemy<2 in /usr/local/lib/python3.10/dist-packages (from obspy) (1.4.54)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from obspy) (4.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from obspy) (2.32.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->obspy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->obspy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->obspy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->obspy) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<2->obspy) (3.1.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install obspy tensorflow matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from obspy import UTCDateTime, Stream, Trace\n",
        "from obspy.clients.fdsn import Client\n",
        "from obspy.signal.trigger import classic_sta_lta\n",
        "from obspy.signal.filter import bandpass\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "hXsHOn5DyE9Q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_iris_data(network, station, location, channel, start_time, end_time):\n",
        "  \"\"\"\n",
        "  Fetch seismic data from IRIS database\n",
        "  \"\"\"\n",
        "  try:\n",
        "    client=Client(\"IRIS\")\n",
        "    stream=client.get_waveforms(network, station, location, channel, start_time, end_time)\n",
        "    return stream\n",
        "  except Exception as e:\n",
        "    print(f\"Error fetching data from IRIS: {str(e)}\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "UJDzTxvtzb9p"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_synthetic_data(num_samples, sample_rate, event_duration, noise_level):\n",
        "  \"\"\"\n",
        "  Generate synthetic seismic data for testing and validation\n",
        "  \"\"\"\n",
        "  time=np.arange(num_samples)/sample_rate\n",
        "  background=np.random.normal(0, noise_level, num_samples)\n",
        "\n",
        "  #Create multiple events for more complex training\n",
        "  num_events=np.random.randint(1,4)\n",
        "  events=np.zeros(num_samples)\n",
        "  event_locations=[]\n",
        "\n",
        "  for _ in range(num_events):\n",
        "    event_start=np.random.randint(num_samples // 8, num_samples * 7//8)\n",
        "    event_end=event_start + int(event_duration *sample_rate)\n",
        "    event_locations.append((event_start, event_end))\n",
        "\n",
        "    #Create event with varying frequency and amplitude\n",
        "    freq=np.random.uniform(3, 8)\n",
        "    amp=np.random.uniform(0.8, 1.2)\n",
        "    decay=np.random.uniform(0.1, 0.3)\n",
        "\n",
        "    event=np.sin(2*np.pi*freq*(time[event_start:event_end]-time[event_start]))*\\\n",
        "          amp*np.exp(-(time[event_start:event_end]-time[event_start])/ decay)\n",
        "    events[event_start:event_end]=event\n",
        "\n",
        "  data =background +events\n",
        "  return data, events, event_locations\n",
        "\n"
      ],
      "metadata": {
        "id": "1LYVY0Vp0Fay"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_windows(data, window_size, step):\n",
        "  \"\"\"\n",
        "  Create sliding windows for RNN input with overlap\n",
        "  \"\"\"\n",
        "  windows=[]\n",
        "  labels=[]\n",
        "\n",
        "  for i in range(0, len(data)- window_size +1, step):\n",
        "    window=data[i:i+window_size]\n",
        "\n",
        "    #Add Feature engineering\n",
        "    window_features=np.column_stack((\n",
        "        window, #raw signal\n",
        "        np.abs(window), #absolute amplitude\n",
        "        np.gradient(window), #First deravitive\n",
        "        np.gradient(np.gradient(window)) #Second derivative\n",
        "    ))\n",
        "    windows.append(window_features)\n",
        "\n",
        "    if len(window)==window_size:\n",
        "      labels.append(window.mean())\n",
        "  return np.array(windows), np.array(labels)"
      ],
      "metadata": {
        "id": "_XeYWuzf0TYJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_enhanced_rnn_model(input_shape):\n",
        "  \"\"\"\n",
        "  Build an enhanced RNN model with multiple LSTM layers and additional features\n",
        "  \"\"\"\n",
        "  model=Sequential([\n",
        "      # First Bidirectional LSTM Layer\n",
        "      Bidirectional(LSTM(128, return_sequences=True), input_shape=input_shape),\n",
        "      BatchNormalization(),\n",
        "      Dropout(0.3),\n",
        "\n",
        "      #Second Bidirectional LSTM layer\n",
        "      Bidirectional(LSTM(96, return_sequences=True)),\n",
        "      BatchNormalization(),\n",
        "      Dropout(0.3),\n",
        "\n",
        "      #Third LSTM Layer\n",
        "      LSTM(64),\n",
        "      BatchNormalization(),\n",
        "      Dropout(0.2),\n",
        "\n",
        "      #Dense layer for classification\n",
        "      Dense(32, activation='relu'),\n",
        "      BatchNormalization(),\n",
        "      Dropout(0.2),\n",
        "      Dense(16, activation='relu'),\n",
        "      Dense(1, activation='sigmoid')\n",
        "\n",
        "  ])\n",
        "\n",
        "  # Use Adam optimizer with custom learning rate\n",
        "  optimizer=Adam(learning_rate=0.001)\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=optimizer,\n",
        "      loss='binary_crossentropy',\n",
        "      metrics=['accuracy', 'Precision', 'Recall']\n",
        "  )\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "uYa6a3Wb3g-F"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_stream(stream, freqmin=0.5, freqmax=20):\n",
        "  \"\"\"\n",
        "  Process a seismic stream with enhanced filtering\n",
        "  \"\"\"\n",
        "  processed_stream=stream.copy()\n",
        "  processed_stream.detrend('linear')\n",
        "  processed_stream.taper(max_percentage=0.05)\n",
        "  processed_stream.filter('bandpass', freqmin=freqmin, freqmax=freqmax,\n",
        "                          corners=4, zerophase=True)\n",
        "  return processed_stream"
      ],
      "metadata": {
        "id": "6AZhJZ9-6vyU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_test, y_test, predictions):\n",
        "  binary_predictions=(predictions>0.5).astype(int)\n",
        "\n",
        "  accuracy=accuracy_score(y_test, binary_predictions)\n",
        "  precision=precision_score(y_test, binary_predictions)\n",
        "  recall=recall_score(y_test, binary_predictions)\n",
        "  f1=f1_score(y_test, binary_predictions)\n",
        "\n",
        "  report=classification_report(y_test, binary_predictions)\n",
        "\n",
        "  cm=confusion_matrix(y_test, binary_predictions)\n",
        "\n",
        "  print(\"\\n===Model Performance Metrics===\")\n",
        "  print(f\"Accuracy:{accuracy:.4f}\")\n",
        "  print(f\"Precision:{precision:.4f}\")\n",
        "  print(f\"Recall:{recall:.4f}\")\n",
        "  print(f\"F1 Score:{f1:.4f}\")\n",
        "\n",
        "  print(\"\\n=== Classification report===\")\n",
        "  print(report)\n",
        "\n",
        "  plt.figure(figsize=(8,6))\n",
        "  sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "  plt.title('Confusion Matrix')\n",
        "  plt.ylabel('True Label')\n",
        "  plt.xlabel('Predicted Label')\n",
        "  plt.show()\n",
        "\n",
        "  return accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "EJCQEdlG7p_1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(use_real_data=True):\n",
        "  #Configuration parameters\n",
        "  config={\n",
        "      'window_size':200,\n",
        "      'step':20,\n",
        "      'sample_rate':100,\n",
        "      'sta_length':50, #0.5 seconds\n",
        "      'lta_length':500, #5 Seconds\n",
        "      'threshold':1.5,\n",
        "      'num_samples':20000\n",
        "  }\n",
        "\n",
        "  if use_real_data:\n",
        "    #Fetch real data from IRIS\n",
        "    end_time=UTCDateTime.now()\n",
        "    start_time=end_time-3600\n",
        "\n",
        "    stream=fetch_iris_data('YS', \"BAOP\", \"\", \"BHZ\", start_time, end_time)\n",
        "    if stream is None:\n",
        "      print(\"Falling back to synthetic data...\")\n",
        "      use_real_data=False\n",
        "    else:\n",
        "      filtered_stream=process_stream(stream)\n",
        "\n",
        "  if not use_real_data:\n",
        "    # Genearate synthetic data with multiple events\n",
        "    synthetic_data, true_events, event_locations=generate_synthetic_data(\n",
        "        config['num_samples'],\n",
        "        config['sample_rate'],\n",
        "        event_duration=2,\n",
        "        noise_level=0.1\n",
        "    )\n",
        "    trace= Trace(data=synthetic_data)\n",
        "    trace.stats.starttime=UTCDateTime(\"2021-01-01T00:00:00\")\n",
        "    trace.stats.delta=1.0/config['sample_rate']\n",
        "    trace.stats.channel='SHZ'\n",
        "    filtered_stream=Stream([trace])\n",
        "    filtered_stream=process_stream(filtered_stream)\n",
        "\n",
        "  #Create training data\n",
        "  X, y=create_windows(\n",
        "      filtered_stream[0].data,\n",
        "      config['window_size'],\n",
        "      config['step']\n",
        "  )\n",
        "  if use_real_data:\n",
        "    #For real data, use STA/LTA triggers as initial labels\n",
        "    triggers, sta_lta=sta_lta_detection(\n",
        "        filtered_stream,\n",
        "        config['sta_length'],\n",
        "        config['lta_length'],\n",
        "        config['threshold']\n",
        "    )\n",
        "    y=(y>config['threshold']).astype(int)\n",
        "  else:\n",
        "    y=(y>0).astype(int)\n",
        "\n",
        "  print(f\"X shape: {X.shape}\")\n",
        "  print(f\"y shape: {y.shape}\")\n",
        "\n",
        "  #Prepare data for training\n",
        "  X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "  #Normalize data\n",
        "  mean=X_train.mean(axis=(0,1), keepdims=True)\n",
        "  std=X_train.std(axis=(0,1), keepdims=True)\n",
        "  X_train=(X_train -mean)/std\n",
        "  X_test=(X_test-mean) /std\n",
        "\n",
        "  #Build and train model\n",
        "  input_shape=(config['window_size'], X.shape[2])\n",
        "  model=build_enhanced_rnn_model(input_shape)\n",
        "\n",
        "  #Add callbacks\n",
        "  callbacks=[\n",
        "      EarlyStopping(\n",
        "          monitor='val_loss',\n",
        "          patience=10,\n",
        "          restore_best_weights=True\n",
        "      ),\n",
        "      ReduceLROnPlateau(\n",
        "          monitor='val_loss',\n",
        "          factor=0.5,\n",
        "          patience=5,\n",
        "          min_lr=1e-6\n",
        "      )\n",
        "  ]\n",
        "  #Train Model\n",
        "  history=model.fit(\n",
        "      X_train, y_train,\n",
        "      epochs=100,\n",
        "      batch_size=32,\n",
        "      validation_split=0.2,\n",
        "      callbacks=callbacks,\n",
        "      verbose=1\n",
        "  )\n",
        "\n",
        "  # Make Predictions\n",
        "  predictions=model.predict(X_test)\n",
        "  accuracy, precision, recall, f1=evaluate_model(model, X_test, y_test, predictions)\n",
        "\n",
        "  #plot results\n",
        "  plot_results(filtered_stream, predictions, config, use_real_data, metrics={'accuracy':accuracy, 'precision': precision, 'recall':recall, 'f1':f1})\n",
        "  plot_training_history(history)"
      ],
      "metadata": {
        "id": "Yf0a8tE6_D0d"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_results(stream, predictions, config, use_real_data, metrics=None):\n",
        "  plt.figure(figsize=(15, 12))\n",
        "\n",
        "  #Plot original data\n",
        "  plt.subplot(3,1,1)\n",
        "  plt.plot(stream[0].data, color='navy', linewidth=1.5)\n",
        "  plt.title(\"Original Seismic Data\", fontsize=12, fontweight='bold')\n",
        "  plt.xlabel(\"Samples\", fontsize=10)\n",
        "  plt.ylabel(\"Amplitude\", fontsize=10)\n",
        "\n",
        "  if metrics:\n",
        "    plt.text(0.02, 0.988,\n",
        "             f\"Accuracy: {metrics['accuracy']:.4f}\\n\"\n",
        "             f\"Precision: {metrics['precision']:.4f}\\n\"\n",
        "             f\"Recall: {metrics['recall']:.4f}\\n\"\n",
        "             f\"F1 Score:{metrics['f1']:.4f}\",\n",
        "             transform=plt.gca().transAxes,\n",
        "             verticalalignment='top',\n",
        "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
        "\n",
        "    plt.subplot(3,1,2)\n",
        "    plt.plot(predictions, color='green', linewidth=1.5, alpha=0.7)\n",
        "    plt.title(\"Detection Prediction Probabilities\", fontsize=12, fontweight='bold')\n",
        "    plt.xlabel(\"Windows\", fontsize=10)\n",
        "    plt.ylabel(\"Probability\", fontsize=10)\n",
        "    plt.ylim(0,1)\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "    plt.subplot(3,1,3)\n",
        "    binary_preds=(predictions>0.5).astype(int)\n",
        "    plt.plot(binary_preds, color='red', linewidth=1.5)\n",
        "    plt.title(\"Binary Predictions(Threshold=0.5)\", fontsize=12, fontweight='bold')\n",
        "    plt.xlabel(\"Windows\", fontsize=10)\n",
        "    plt.ylabel(\"Detection\", fontsize=10)\n",
        "    plt.ylim(-0.1, 1.1)\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "8_FXGGUBGEkV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_history(history):\n",
        "  plt.figure(figsize=(15,5))\n",
        "\n",
        "  plt.subplot(1,3,1)\n",
        "  plt.plot(history.history['loss'], label=\"Training Loss\", color='blue')\n",
        "  plt.plot(history.history['val_loss'], label='Validatio loss', color='red')\n",
        "  plt.title('Model Loss', fontsize=12, fontweight='bold')\n",
        "  plt.xlabel('Epoch', fontsize=10)\n",
        "  plt.ylabel('loss', fontsize=10)\n",
        "  plt.legend()\n",
        "  plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "  plt.subplot(1,3,2)\n",
        "  plt.plot(history.history['accuracy'], label='Training accuracy', color='green')\n",
        "  plt.plot(history.history['val_accuracy'], label='Validation accuracy', color='orange')\n",
        "  plt.title('Model Accuracy', fontsize=12, fontweight='bold')\n",
        "  plt.xlabel('Epoch', fontsize=10)\n",
        "  plt.ylabel('Accuracy', fontsize=10)\n",
        "  plt.legend()\n",
        "  plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "  plt.subplot(1,3,3)\n",
        "  plt.plot(history.history['Precision'], label='Precision', color='purple')\n",
        "  plt.plot(history.history['Recall'], label='Recall', color='brown')\n",
        "  plt.title('Precision and Recall', fontsize=12, fontweight='bold')\n",
        "  plt.xlabel('Epoch', fontsize=10)\n",
        "  plt.ylabel('Score', fontsize=10)\n",
        "  plt.legend()\n",
        "  plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "  plt.tight_layout(pad=3.0)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "A18acwHgI9_q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__==\"__main__\":\n",
        "  main(use_real_data=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_HqQu76LPC7",
        "outputId": "99c92185-2553-4b42-9789-c9a84688ed1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error fetching data from IRIS: No data available for request.\n",
            "HTTP Status code: 204\n",
            "Detailed response of server:\n",
            "\n",
            "\n",
            "Falling back to synthetic data...\n",
            "X shape: (991, 200, 4)\n",
            "y shape: (991,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - Precision: 0.5076 - Recall: 0.8349 - accuracy: 0.5128 - loss: 0.8848 - val_Precision: 0.5946 - val_Recall: 0.3607 - val_accuracy: 0.6115 - val_loss: 0.6824 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - Precision: 0.5843 - Recall: 0.7850 - accuracy: 0.6117 - loss: 0.7036 - val_Precision: 0.6667 - val_Recall: 0.4262 - val_accuracy: 0.6547 - val_loss: 0.6750 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - Precision: 0.7018 - Recall: 0.7040 - accuracy: 0.6915 - loss: 0.5920 - val_Precision: 0.7059 - val_Recall: 0.5902 - val_accuracy: 0.7122 - val_loss: 0.6555 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - Precision: 0.6222 - Recall: 0.7243 - accuracy: 0.6530 - loss: 0.6186 - val_Precision: 0.7381 - val_Recall: 0.5082 - val_accuracy: 0.7050 - val_loss: 0.6405 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - Precision: 0.7545 - Recall: 0.7370 - accuracy: 0.7302 - loss: 0.5434 - val_Precision: 0.6286 - val_Recall: 0.7213 - val_accuracy: 0.6906 - val_loss: 0.6423 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - Precision: 0.7023 - Recall: 0.7547 - accuracy: 0.6992 - loss: 0.5638 - val_Precision: 0.6727 - val_Recall: 0.6066 - val_accuracy: 0.6978 - val_loss: 0.6210 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - Precision: 0.7787 - Recall: 0.7860 - accuracy: 0.7700 - loss: 0.5226 - val_Precision: 0.6667 - val_Recall: 0.6557 - val_accuracy: 0.7050 - val_loss: 0.5940 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - Precision: 0.7732 - Recall: 0.7486 - accuracy: 0.7522 - loss: 0.4889 - val_Precision: 0.6486 - val_Recall: 0.7869 - val_accuracy: 0.7194 - val_loss: 0.5885 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step - Precision: 0.7661 - Recall: 0.7236 - accuracy: 0.7300 - loss: 0.5322 - val_Precision: 0.5556 - val_Recall: 0.8197 - val_accuracy: 0.6331 - val_loss: 0.6475 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - Precision: 0.6393 - Recall: 0.6387 - accuracy: 0.6253 - loss: 0.6673 - val_Precision: 0.5000 - val_Recall: 0.9016 - val_accuracy: 0.5612 - val_loss: 0.6673 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - Precision: 0.6545 - Recall: 0.7252 - accuracy: 0.6721 - loss: 0.6265 - val_Precision: 0.5192 - val_Recall: 0.8852 - val_accuracy: 0.5899 - val_loss: 0.6318 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2s/step - Precision: 0.6393 - Recall: 0.5987 - accuracy: 0.6248 - loss: 0.6412 - val_Precision: 0.5714 - val_Recall: 0.8525 - val_accuracy: 0.6547 - val_loss: 0.6157 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - Precision: 0.7187 - Recall: 0.7300 - accuracy: 0.7150 - loss: 0.5422 - val_Precision: 0.6765 - val_Recall: 0.3770 - val_accuracy: 0.6475 - val_loss: 0.6274 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - Precision: 0.6909 - Recall: 0.6936 - accuracy: 0.7039 - loss: 0.5787 - val_Precision: 0.4683 - val_Recall: 0.9672 - val_accuracy: 0.5036 - val_loss: 1.5457 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - Precision: 0.7057 - Recall: 0.7137 - accuracy: 0.6851 - loss: 0.5885 - val_Precision: 0.4724 - val_Recall: 0.9836 - val_accuracy: 0.5108 - val_loss: 1.3122 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n"
          ]
        }
      ]
    }
  ]
}